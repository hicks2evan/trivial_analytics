{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.6.0 64-bit",
   "display_name": "Python 3.6.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "05ece30799c2dcdac4c13b3af20453da19de8df0d9a1de52cff7e0b6e1e82bdd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Trivial Analytics\n",
    "The purpose of this post is to try to use some data analytics to answer a question that came up in a conversation between me and my trivia teammates. Before the coronavirus put our favorite bar trivia night on hold, my friends and I had a ritual of appearing there every Wednesday night at 7pm and answering 8 rounds of trivia questions on a variety of [geek pop-culture subjects](https://www.geekswhodrink.com/). The question that arose at our table was along these lines:\n",
    "\n",
    "> What would you give to know the 10 most important topics to study for trivia?\n",
    "\n",
    "It's pretty natural to start to try to answer this question with data. For our particular trivia game, if we had the data it would be great to know which *things* appear the most in questions and answers. Knowing, for example, that Beyonce is 10% more likely to appear in an audio round than Bruno Mars is a pretty critical piece of information for somebody with a limited amount of time to prepare to win that sweet, sweet $20 bar cash.\n",
    "\n",
    "Extracting this type of insight is 'non-trivial', even assuming a perfect world where I had access to a data set with my bar trivia game's questions and answers. No such data set exists. But, after some sleuthing I found a reddit poster sharing a data set with 200,000+ Jeopardy! questions [here](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/). Bad news for my trivia team, I don't have the resources to crack the code our game, but maybe we can learn something by asking an amended question of the Jeopardy! data:\n",
    "\n",
    "> If you only could study 10 topics in preparation for Jeopardy!, which topics should you study?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Working with the data\n",
    "The first step was to set up the data in a way that would be easy for me to work with in this project. I spun up a mySQL database and added a `question` table to hold the question data from reddit. There were a number of columns that I imported, but mostly we care about the `question` and `answer` fields.\n",
    "\n",
    "The Juptyer notebook for this post is set up to easily connect to a local mySQL database assuming it is set up a similar way. Python can connect to mySQL using a package called `mysql.connector`."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "\n",
    "def connectToMySQL():\n",
    "  mydb = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"service\",\n",
    "    password=\"jeopardy!\",\n",
    "  )\n",
    "  print(\"Connected.\")\n",
    "  print()\n",
    "  return mydb\n",
    "\n"
   ]
  },
  {
   "source": [
    "With a connection to the database open, you can execute normal SQL queries. Right away we are able to ask some fairly smart things if we know what we are looking for, like *show me five questions about Egypt*."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Connected.\n\nQuestion: | 'Cleopatra's Needle is a short walk from this Egyptian Temple in the Metropolitan Museum of Art'\nAnswer:   | the Temple of Dendur\n\nQuestion: | 'In 46 B.C. this Egyptian came with Caesar to Rome, where her statue was placed in the temple of Venus Genetrix'\nAnswer:   | Cleopatra\n\nQuestion: | '\"The Prince of Egypt\" featured Ralph Fiennes as the voice of this stubborn ruler'\nAnswer:   | the Pharaoh\n\nQuestion: | 'This city of east central Egypt is the southern half of the site of ancient Thebes'\nAnswer:   | Luxor\n\nQuestion: | 'A short war between Israel & Egypt & Syria in October 1973 was named for this high holiday'\nAnswer:   | Yom Kippur\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "mydb = connectToMySQL()\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\"SELECT question, answer FROM jeapordy_questions.question WHERE question like '%Egypt%' LIMIT 5\")\n",
    "\n",
    "for (question, answer) in cursor:\n",
    "    print(\"Question: | \" + question)\n",
    "    print(\"Answer:   | \" + answer)\n",
    "    print()\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "source": [
    "So now we have a database set up and we can write queries to ask it smart things. Like mentioned above, however, this requires us to know what we are asking. Questions like *what 10 things should I study* won't fly because we can't write a query yet for *things* we don't know we care about. We need some way to figure out what *things* in the questions are important."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Named Entity Recognition\n",
    "So what do I mean by *thing*? One naive solution to our problem might be to just look for common appearances of certain words. For example, if \"America\" appears regularly in questions, then that might be an important country to study, right?Well, practiced trivia players know that trivia is all about going more fine-grained than that. American History may be a very important subject to study, but at the end of the day, you may need to know some specifics about Hamilton that you may gloss over if you only study American History broadly. \n",
    "\n",
    "Consider another issue of the word count solution, it may tell you that it is quite important to know about \"Alexander\", but *Alexander-who?* Alexander Hamilton and Alexander the Great might both be important, but the word count solution doesn't tell us who is *more* important.\n",
    "\n",
    "Another idea is to use the `category` of a question. That should help us get to the meat of what a question is about, but viewers of Jeopardy! will know well that the category is usually not useful, if not downright distracting. Categories like \"African Geography\" are way too broad to be useful. Meanwhile, many of the Jeapordy! categories are unique to the game, playful rhymes or word games.\n",
    "\n",
    "In general, it looks like we are trying to extract people, places, times, etc. from the questions. In Natural Language Processing (NLP) there is a name for annotating this type of information, \"Named Entity Recognition\". Fortunately there are handy Python libraries out there like [spaCy](https://spacy.io/api/entityrecognizer) that can do the heavy lifting for this.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('The Prince of Egypt', 'WORK_OF_ART'), ('Ralph Fiennes', 'PERSON')]\n"
    }
   ],
   "source": [
    "# Reference https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from collections import Counter\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "def printAnnotation(q):\n",
    "    doc = nlp(q)\n",
    "    print([(X.text, X.label_) for X in doc.ents])\n",
    "\n",
    "# We won't use this function right away, but let's set it up now so we can use it later\n",
    "def getAnnotation(q):\n",
    "    return nlp(q)\n",
    "\n",
    "q = '\"The Prince of Egypt\" featured Ralph Fiennes as the voice of this stubborn ruler'\n",
    "printAnnotation(q)"
   ]
  },
  {
   "source": [
    "Here we can see spaCy was able to identidy to named entities in this question, \"The Prince of Egypt\" was labeled as a work of art (animated film, go watch it), and \"Ralph Fiennes\" was labeled as a person. This works pretty well generally, but it isn't perfect. For example, below it has decided that \"Israel & Egypt & Syria\" are an organization all-together. Hopefully these things will *come out in the wash* so to speak, but we should keep an eye out for misleading entities.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[('Israel & Egypt & Syria', 'ORG'), ('October 1973', 'DATE')]\n"
    }
   ],
   "source": [
    "q = \"A short war between Israel & Egypt & Syria in October 1973 was named for this high holiday\"\n",
    "printAnnotation(q)"
   ]
  },
  {
   "source": [
    "## Mapping Questions to Named Entities\n",
    "To map question and answer text to Named Entities, we need a new table to track those entities and their types, as well as a mapping table to handle the many to many relationship of question to named_entity. With that set up and foreign keys in place, I should be able to populate those tables pretty easily.\n",
    "\n",
    "This seeding script reads questions and answers from the database, creates named enitities and maps them to questions by inserting rows in named_entitu and mapping rows in question_named_entity. For now it is ignoring CARDINAL and MONEY named entities, as I found them to be not so useful (examples: 100, $1 billing, etc.)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to get all questions from question table with limit and offset to paginate\n",
    "get_all_questions = (\"SELECT question_id, question, answer FROM jeapordy_questions.question LIMIT %s OFFSET %s\")\n",
    "\n",
    "# Queries to wipe out tables before re-seeding\n",
    "delete_mappings = \"DELETE FROM jeapordy_questions.question_named_entity\"\n",
    "delete_named_entities = \"DELETE FROM jeapordy_questions.named_entity\"\n",
    "\n",
    "# Queries to add named entities and mappings\n",
    "add_named_entity = (\"INSERT INTO jeapordy_questions.named_entity (name, type) VALUES (%s, %s)\")\n",
    "add_mapping = (\"INSERT INTO jeapordy_questions.question_named_entity (question, named_entity) VALUES (%s, %s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Deleting old records...\nStarting get...\n(10000, 0)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 10000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 20000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 30000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 40000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 50000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 60000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 70000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 80000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 90000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 100000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 110000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 120000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 130000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 140000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 150000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 160000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 170000)\nDone, starting mapping...\nDone, starting insert...\nStarting get...\n(10000, 180000)\nDone, starting mapping...\nDone, starting insert...\nDone, closing...\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "mydb = connectToMySQL()\n",
    "cursor = mydb.cursor()\n",
    "\n",
    "print(\"Deleting old records...\")\n",
    "cursor.execute(delete_mappings)\n",
    "cursor.execute(delete_named_entities)\n",
    "mydb.commit()\n",
    "\n",
    "limit = 10000\n",
    "offset = 0\n",
    "data_entities = dict()\n",
    "all_data_entities = dict()\n",
    "data_mappings = []\n",
    "\n",
    "for i in range(limit, 200000, limit):\n",
    "  print(\"Starting get...\")\n",
    "  get_data = (limit, offset)\n",
    "  print(str(get_data))\n",
    "  cursor.execute(get_all_questions, get_data)\n",
    "\n",
    "  print(\"Done, starting mapping...\")\n",
    "  for (question_id, question, answer) in cursor:\n",
    "      q = unidecode.unidecode(regex.sub(\"'\", \"\", question + \" \" + answer))\n",
    "      doc = getAnnotation(q)\n",
    "      for X in doc.ents:\n",
    "        if not X.label_ == 'CARDINAL' and not X.label_ == 'MONEY':\n",
    "          entity = X.text.lower()\n",
    "          if not entity in data_entities:\n",
    "            if not entity in all_data_entities:\n",
    "              data_entities[entity] = X.label_\n",
    "          data_mapping = (question_id, entity)\n",
    "          data_mappings.append(data_mapping)\n",
    "  print(\"Done, starting insert...\")\n",
    "  cursor.executemany(add_named_entity, (list(data_entities.items())))\n",
    "  mydb.commit()\n",
    "  cursor.executemany(add_mapping, (data_mappings))\n",
    "  mydb.commit()\n",
    "\n",
    "  all_data_entities = {**all_data_entities, **data_entities} \n",
    "  data_entities.clear()\n",
    "  data_mappings = []\n",
    "  offset = i\n",
    "print(\"Done, closing...\")\n",
    "cursor.close()"
   ]
  },
  {
   "source": [
    "With that in place, we should be able to query the mapping table for information about occurrences of certain named entities in questions. We should be able to write a rudimentary query to answer our question- what are the most important topics to study?"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('first', 7848)\n('u.s.', 3895)\n('french', 2251)\n('british', 1687)\n('greek', 1449)\n('american', 1388)\n('latin', 1386)\n('english', 1068)\n('second', 1004)\n('german', 957)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"service\",\n",
    "  password=\"jeopardy!\",\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\"SELECT named_entity,COUNT(*) FROM jeapordy_questions.question_named_entity GROUP BY named_entity ORDER BY COUNT(*) DESC LIMIT 10;\")\n",
    "\n",
    "for r in cursor:\n",
    "    print(str(r))\n",
    "cursor.close()"
   ]
  },
  {
   "source": [
    "We're getting closer. Not too surprisingly, we see frequent occurences of what look like geographic or linquistic designations- French, American, English, Greek, German. First and Second don't really seem like topics, but more like just a part of speech, let's look into that."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(\"'Cows regurgitate this from the first stomach to the mouth & chew it again'\", 'ORDINAL')\n(\"'Karl led the first of these Marxist organizational efforts; the second one began in 1889'\", 'ORDINAL')\n('\\'This \"Modern Girl\" first hit the Billboard Top 10 with \"Morning Train (Nine To Five)\"\\'', 'ORDINAL')\n(\"'Warhol became the manager of this Lou Reed rock group in 1965 & produced their first album'\", 'ORDINAL')\n(\"'His first act after being sworn in as president of the Confederacy was to send a peace commission to Washington, D.C.'\", 'ORDINAL')\n(\"'The first 50-star U.S. flag was officially raised on July 4 of this year'\", 'ORDINAL')\n('\\'On March 19, 2009 he said, \"I\\'m excited and honored to introduce my first guest... Barack Obama\"\\'', 'ORDINAL')\n(\"'The first controlled nuclear chain reaction'\", 'ORDINAL')\n('\\'He reviewed films & TV for the New Republic before his first book, \"Goodbye, Columbus\", was published in 1959\\'', 'ORDINAL')\n(\"'Colo was the first of these great apes born in captivity, in 1956 at the Columbus Zoo'\", 'ORDINAL')\n('\\'\"In 1997, the House (of Reps.) voted to reprimand him... It marked the first time the House had reprimanded a Speaker\"\\'', 'ORDINAL')\n('\\'Ed White, the first U.S. spacewalker, lost one of these outside Gemini 4; he must\\'ve looked like a later \"moonwalker\"\\'', 'ORDINAL')\n(\"'In 1948 Douglas Edwards became the first anchor of this network's Evening News'\", 'ORDINAL')\n(\"'When speaking of Messrs. Netanyahu or Britten, it's all about the first name, pluralized'\", 'ORDINAL')\n(\"'In 1905 German scientist Alfred Einhorn created this first injectable local anesthetic used in dentistry'\", 'ORDINAL')\n(\"'In 1986 Mexico scored as the first country to host this international sports competition twice'\", 'ORDINAL')\n('\\'On March 2, 1977 he made his first \"Tonight Show\" appearance; on May 25, 1992 he took over as host\\'', 'ORDINAL')\n(\"'During the war, this first signer of the Declaration of Independence commanded the Mass. Militia'\", 'ORDINAL')\n(\"'In 960 Mieczyslaw I became the first ruler of this country'\", 'ORDINAL')\n(\"'Quit your yellin' & name this 1995 hit duet for Michael & Janet Jackson, their first together'\", 'ORDINAL')\n(\"'In 1960 this Democrat spoke first in the first televised U.S. presidential election debate'\", 'ORDINAL')\n(\"'In 1960 this Democrat spoke first in the first televised U.S. presidential election debate'\", 'ORDINAL')\n(\"'Likely containing a sandwich, the first of these depicting a TV character came along in 1950 with Hopalong Cassidy'\", 'ORDINAL')\n(\"'As they were partial to using hymns, these brothers, Charles & John, were the first rhythm Methodists'\", 'ORDINAL')\n(\"'In 1980 Dial-It National Sports became the first service on this new area code'\", 'ORDINAL')\n(\"'Helen Keller brought the first of these Japanese dogs to the United States in 1937'\", 'ORDINAL')\n(\"'In Genesis 4 he becomes the first killer; God isn't happy'\", 'ORDINAL')\n(\"'The first 10 of these are known as the Bill of Rights'\", 'ORDINAL')\n(\"'The first 4 letters of xylophone refer etymologically to this material used to make its sounding bars'\", 'ORDINAL')\n(\"'Something that's the first son's due; Esau sold his'\", 'ORDINAL')\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"service\",\n",
    "  password=\"jeopardy!\",\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\n",
    "    \"SELECT question.question, named_entity.type FROM jeapordy_questions.question_named_entity \" + \n",
    "    \"LEFT JOIN jeapordy_questions.question \" +\n",
    "    \"ON jeapordy_questions.question.question_id = jeapordy_questions.question_named_entity.question \" +\n",
    "    \"LEFT JOIN jeapordy_questions.named_entity \" +\n",
    "    \"ON jeapordy_questions.question_named_entity.named_entity = jeapordy_questions.named_entity.name \" +\n",
    "    \"WHERE jeapordy_questions.question_named_entity.named_entity = 'first' LIMIT 30;\")\n",
    "\n",
    "for r in cursor:\n",
    "    print(str(r))\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "source": [
    "That looks like enough information to rule out ORDINAL. Out of curiosity lets repeat this process for things like American, or German. Maybe there is another broad category to rule out."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(\"'In 1811 this German family began its steel-making business by constructing a plant in Essen'\", 'NORP')\n(\"'In 1905 German scientist Alfred Einhorn created this first injectable local anesthetic used in dentistry'\", 'NORP')\n('\\'Some of these are produced by bremsstrahlung, from the German for \"breaking radiation\"\\'', 'NORP')\n(\"'Named for a German neuropathologist, this memory loss disease may be caused by a gene on chromosome 21'\", 'NORP')\n(\"'This German composer's 5th Symphony in C Minor has a famous opening'\", 'NORP')\n(\"'In German, berg is this topographical feature on a map'\", 'NORP')\n(\"'The U.S. U-2, first built in the 1950s, was an airplane; the German U-1, first built in the 1910s, was one of these'\", 'NORP')\n(\"'Paul Baumer, a young German soldier'\", 'NORP')\n(\"'A German circus performer has made the Guinness record book for riding a bicycle with this distinction'\", 'NORP')\n(\"'Laboratory culture dish named for the German bacteriologist who invented it'\", 'NORP')\n('\\'In \"Sahara\", set in this war, German soldiers attack Humphrey Bogart at a desert oasis\\'', 'NORP')\n(\"'In the 16th century, Munich was a center of the German phase of this movement against Protestantism'\", 'NORP')\n('\\'Brought to the U.S. in the 1930s, this movement\\'s name is German for \"pattern\" or \"shape\"\\'', 'NORP')\n(\"'In 1919 this national assembly met in this city & formed a new German republic'\", 'NORP')\n('\\'Fritz & Laura Perls founded this school of psychotherapy, from German for \"form\"\\'', 'NORP')\n(\"'By pure reason you should know he's the categorical German seen here'\", 'NORP')\n(\"'The name of this German publisher has become synonymous  with a guidebook'\", 'NORP')\n(\"'This Latvian capital was founded in 1201 by German crusaders'\", 'NORP')\n(\"'Known as Wandermeisen in German, these conspicuously mobile ants move about in long, orderly columns'\", 'NORP')\n(\"'The forehead of a German mrs.'\", 'NORP')\n(\"'This German-born American physicist won the 1921 Nobel Prize for Physics'\", 'NORP')\n(\"'Crossed by numerous canals, it's said that this German port has more bridges than Amsterdam & Venice combined'\", 'NORP')\n('\\'This term, German for \"lightning war,\" was used to describe the rapid capture of Poland by Germany in 1939\\'', 'NORP')\n(\"'Construction began on this German city's Gothic cathedral near the Rhine in 1248 & lasted 632 years'\", 'NORP')\n(\"'These common, crawly apartment insects have German, brown-banded & American species'\", 'NORP')\n(\"'The 1st of these high-speed German highways was opened between Cologne & Bonn in 1932'\", 'NORP')\n(\"'On March 23 this German parliament relinquished its power to Adolf Hitler'\", 'NORP')\n('\\'Strangely, this \"colorful\" German company sells its classic travel alarm clocks only in black & white\\'', 'NORP')\n(\"'German sausage named for the crackling sound the skin of the sausage makes when bitten into'\", 'NORP')\n('\\'For dessert, bring me some of this apple-filled rolled pastry whose name is from the German for \"whirlpool\"\\'', 'NORP')\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"service\",\n",
    "  password=\"jeopardy!\",\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\n",
    "    \"SELECT question.question, named_entity.type FROM jeapordy_questions.question_named_entity \" + \n",
    "    \"LEFT JOIN jeapordy_questions.question \" +\n",
    "    \"ON jeapordy_questions.question.question_id = jeapordy_questions.question_named_entity.question \" +\n",
    "    \"LEFT JOIN jeapordy_questions.named_entity \" +\n",
    "    \"ON jeapordy_questions.question_named_entity.named_entity = jeapordy_questions.named_entity.name \" +\n",
    "    \"WHERE jeapordy_questions.question_named_entity.named_entity = 'german' LIMIT 30;\")\n",
    "\n",
    "for r in cursor:\n",
    "    print(str(r))\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "source": [
    "Seems like NORP might be worth ruling out also. At this point I am starting to wonder if it is less about NLP labels we don't care about, and more about the few we DO care about. Interestingly, the first appearance of a topic that feels \"trivial\" in nature is \"The Clue Crew\" with 357 occurrences in questions. Let's take a look at those results and see how it is labeled. \"The Clue Crew\", obviously the group from the Nancy Drew childrens book series, is labeld as an \"ORG\". Logically seems like if we care about organizations, we also care about people."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "('congress', 388)\n('nyc', 359)\n('the clue crew', 357)\n('shakespeare', 287)\n('jesus', 274)\n('senate', 257)\n('sarah', 232)\n('house', 220)\n('nba', 219)\n('john', 210)\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "import mysql.connector\n",
    "\n",
    "mydb = mysql.connector.connect(\n",
    "  host=\"localhost\",\n",
    "  user=\"service\",\n",
    "  password=\"jeopardy!\",\n",
    ")\n",
    "\n",
    "cursor = mydb.cursor()\n",
    "cursor.execute(\n",
    "    \"SELECT named_entity.name, COUNT(*) FROM jeapordy_questions.question_named_entity \" + \n",
    "    \"LEFT JOIN jeapordy_questions.named_entity \" +\n",
    "    \"ON jeapordy_questions.question_named_entity.named_entity = jeapordy_questions.named_entity.name \" +\n",
    "    \"WHERE jeapordy_questions.named_entity.type = 'ORG' OR jeapordy_questions.named_entity.type = 'PERSON'\" +\n",
    "    \"GROUP BY named_entity ORDER BY COUNT(*) DESC LIMIT 10;\")\n",
    "\n",
    "for r in cursor:\n",
    "    print(str(r))\n",
    "\n",
    "cursor.close()"
   ]
  },
  {
   "source": [
    "By merging our two queries together, paying attention to occurrences of entities by name as long as their label is either a person or an organization, we can quickly see that a student of the game (or any well-rounded individual I suppose) would benefit by reading up on the U.S. Congress, the city of new york, Nancy Drew, Shakespeare, and Jesus."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}